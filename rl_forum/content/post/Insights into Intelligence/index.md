---
title: Insights into Intelligence
description: Rich Sutton
date: 2023-03-17
publishdate: 2022-05-06
slug: insights-intelligence
image: sutton_banner.jpeg
categories:
    - Alberta
    - Upcoming
---

### Logistics
<p>
    <strong> Time:</strong> 3:00-4:00 PM; Friday 3/17/2023<br>
    Hybrid Lecture <br>
    <strong>Locations:</strong> Hewlet 200, <br><br>
</p>

### Presenter
<p>
    Rich Sutton<br>
    Professor,<br>
    Unversity of Alberta<br>
</p>

### Abstract
<p>
    For thousands of years, great philosophers, and later, great scientists, have sought to understand intelligence and thereby better understand themselves. As Richard Feynman said “What I cannot create, I do not understand”, so now as we have begun to create intelligence in machines, we might expect to have gained a greater understanding of it. Has this happened? When I step back, looking past the hype and noise, I do feel that I have gained significant insights into intelligence, summarized below in bullet points. Some of these you may see as obviously true, others as unproven, and still others as simply wrong. Some are not claims at all, but simply definitions (though still arguably insights). I offer them in the spirit of openness and provocation.
    Intelligence is not the ability to mimic people, but rather the ability to achieve goals
    Goals are well formulated as maximizing an externally received number (reward)
    Intelligence is the domain-independent part of the ability to achieve goals
    The world is generally much bigger and more complex than the intelligent agent
    Accordingly, the agent’s computational resources, however great, are never enough
    The above properties of the problem of intelligence require solutions in which the agent is divided into four parts, all learned: perception (state construction), reactive policy, value function, and state-transition model. Similar separations appear in many disparate fields
    The agent further shapes its higher-level cognition by posing subproblems for itself
    Off-policy learning and temporal abstraction are essential ambitions
    In this talk I will explain some of these purported insights and assess their accuracy, significance, and implications.
</p>

### Reference
<p>
</p>

### Bio
<p>
    Richard S. Sutton is a professor in the Department of Computing Science at the University of Alberta and a fellow of the Royal Society of London, the Royal Society of Canada, the Association for the Advancement of Artificial Intelligence, the Alberta Machine Intelligence Institute (Amii), and CIFAR. He received a PhD in computer science from the University of Massachusetts in 1984 and a BA in psychology from Stanford University in 1978. Prior to joining the University of Alberta in 2003, he worked in industry at AT&T Labs and GTE Labs, and in academia at the University of Massachusetts. He helped found DeepMind Alberta in 2017 and worked there until its dissolution in 2023. At the University of Alberta, Sutton founded the Reinforcement Learning and Artificial Intelligence Lab, which now consists of ten principal investigators and about 100 people altogether.
    Sutton's research interests center on the learning problems facing a decision-making agent interacting with its environment, which he sees as central to intelligence. He has additional interests in animal learning psychology, in connectionist networks, and generally in systems that continually improve their representations and models of the world. He is co-author of the textbook Reinforcement Learning: An Introduction. His scientific publications have been cited more than 100,000 times. He is also a libertarian, a chess player, and a cancer survivor.</a>
</p>

### Recording
<p>
</p>
