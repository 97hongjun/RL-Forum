<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Austin on Stanford RL Forum</title>
    <link>https://97hongjun.github.io/categories/austin/</link>
    <description>Recent content in Austin on Stanford RL Forum</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 May 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://97hongjun.github.io/categories/austin/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building RLHF around psychological models of human preference</title>
      <link>https://97hongjun.github.io/p/rlhf-preference/</link>
      <pubDate>Thu, 29 May 2025 00:00:00 +0000</pubDate>
      
      <guid>https://97hongjun.github.io/p/rlhf-preference/</guid>
      <description>Logistics   Time: 3:00-4:00 PM; 05/29/2025
 Location: 380-380Y, Sloan Math Corner Presenter  Brad Knox
Assistant Professor,
Computer Science Department,
University of Texas at Austin
Abstract  RLHF algorithms assume a preference probability function, a mapping from a human&#39;s desires to preference labels, given a pair of options. This mapping is effectively a psychological model of how humans form preferences and is used in RLHF to invert a preference dataset to infer the hidden desires of humans.</description>
    </item>
    
  </channel>
</rss>
