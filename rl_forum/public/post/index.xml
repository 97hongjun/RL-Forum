<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Stanford RL Forum</title>
    <link>https://97hongjun.github.io/post/</link>
    <description>Recent content in Posts on Stanford RL Forum</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 31 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://97hongjun.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Epistemic Neural Networks</title>
      <link>https://97hongjun.github.io/p/epistemic-neural-networks/</link>
      <pubDate>Tue, 31 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://97hongjun.github.io/p/epistemic-neural-networks/</guid>
      <description>Logistics   Time: 4:00-5:00 PM; Tuesday 5/31/2022
Hybrid Lecture Locations: Packard 101, Zoom Link
Presenter  Ian Osband
Research Scientist,
DeepMind, Mountain View
Abstract  Effective decision, exploration, and adaptation often require an agent to know what it knows and, also, what it does not know. This capability relies on the quality of joint predictions of labels assigned to multiple inputs. Conventional neural networks lack this capability and, since most research has focused on marginal predictions, this shortcoming has been largely overlooked.</description>
    </item>
    
    <item>
      <title>Optimal Clustering with Bandit Feedback</title>
      <link>https://97hongjun.github.io/p/optimal-clustering/</link>
      <pubDate>Tue, 24 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://97hongjun.github.io/p/optimal-clustering/</guid>
      <description>Logistics   Time: 2:00-3:00 PM; 5/24/2022
Zoom Link
Presenter  Vincent Y. F. Tan
Associate Professor and Dean&#39;s Chair
Deparrtment of Electrical and Computer Engineering
Department of Mathematics
National University of Singapore
Abstract  This paper considers the problem of online clustering with bandit feedback. A set of arms (or items) can be partitioned into various groups that are unknown. Within each group, the observations associated to each of the arms follow the same distribution with the same mean vector.</description>
    </item>
    
    <item>
      <title>Adaptivity and Confounding in Multi-Armed Bandit Experiments</title>
      <link>https://97hongjun.github.io/p/adaptive-confounding-bandit/</link>
      <pubDate>Thu, 03 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://97hongjun.github.io/p/adaptive-confounding-bandit/</guid>
      <description>Logistics   Time: 4:00-5:00 PM; 3/3/2022
 Zoom Link:  https://stanford.zoom.us/meeting/register/tJckfuCurzkvEtKKOBvDCrPv3McapgP6HygJ Presenter  Daniel Russo
Associate Professor of Decision, Risk, and Operations division of Columbia Business School,
Columbia Business School
Abstract  Multi-armed bandit algorithms minimize experimentation costs required to converge on optimal behavior. They do so by rapidly adapting experimentation effort away from poorly performing actions as feedback is observed. But this desirable feature makes them sensitive to confounding, which is the primary concern underlying classical randomized controlled trials.</description>
    </item>
    
    <item>
      <title>Reinforcement Learning, Bit by Bit</title>
      <link>https://97hongjun.github.io/p/rl-bit-by-bit/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://97hongjun.github.io/p/rl-bit-by-bit/</guid>
      <description>Presenter  Xiuyuan (Lucy) Lu
Research Scientist,
DeepMind, Mountain View
Abstract  Reinforcement learning agents have demonstrated remarkable achievements in simulated environments. Data efficiency poses an impediment to carrying this success over to real environments. The design of data-efficient agents calls for a deeper understanding of information acquisition and representation. We develop concepts and establish a regret bound that together offer principled guidance. The bound sheds light on questions of what information to seek, how to seek that information, and what information to retain.</description>
    </item>
    
    <item>
      <title>Provable Model-based Nonlinear Bandit and Reinforcement Learning</title>
      <link>https://97hongjun.github.io/p/provable-model-based-bandit-rl/</link>
      <pubDate>Thu, 15 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://97hongjun.github.io/p/provable-model-based-bandit-rl/</guid>
      <description>Presenter  Tengyu Ma
Assistant Professor of Computer Science and Statistics,
Stanford
Abstract  Deep model-based reinforcement learning methods have achieved state-of-the-art sample efficiency but we lack a theoretical understanding of them. This talk will first show that convergence to a global maximum requires an exponential number of samples even for a one-layer neural net bandit problem, which is strictly easier than RL. Therefore, we propose to study convergence to local maxima.</description>
    </item>
    
    <item>
      <title>Diffusion Asymptotics for Sequential Experiments</title>
      <link>https://97hongjun.github.io/p/diffusion-asymptotic-sequential-exp/</link>
      <pubDate>Tue, 23 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://97hongjun.github.io/p/diffusion-asymptotic-sequential-exp/</guid>
      <description>Presenter  Kuang Xu
Associate Professor of Operations, Information and Technology,
Stanford Graduate School of Business
Abstract  I will discuss in this talk a new diffusion-asymptotic analysis for sequentially randomized experiments. Rather than taking sample size n to infinity while keeping the problem parameters fixed, we let the mean signal level scale to the order 1/\sqrt{n} so as to preserve the difficulty of the learning task as n gets large.</description>
    </item>
    
    <item>
      <title>Lectures on Information Directed Sampling</title>
      <link>https://97hongjun.github.io/p/lec-ids/</link>
      <pubDate>Mon, 11 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://97hongjun.github.io/p/lec-ids/</guid>
      <description>Presenter  Tor Lattimore
Research Scientist,
Deepmind, London
Abstract  Tor will give a whirlwind tour of a series of recent papers on the information directed sampling algorithm for sequential decision-making. The results come in three flavours. First, generalising and applying the IDS algorithm to problems with a rich information structure such as convex bandits and partial monitoring. Second, showing a connection between the optimisation problem solved by IDS and the optimisation problem that determines the asymptotic lower bound for stochastic structured bandit problems.</description>
    </item>
    
  </channel>
</rss>
